{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "066e4601-571c-4982-a693-c473ac4eeff7",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7bb11d0-b037-4087-acee-9da0acc98fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5b9151-82c9-4317-b8d6-4963e1de9a5e",
   "metadata": {},
   "source": [
    "### Generator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5455d0d4-2fdf-4292-ab39-935f8edd3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, laten_dim, channels):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.channels = channels\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ac701-efd2-4ecb-81ab-7a6cdc91ae50",
   "metadata": {},
   "source": [
    "### Discriminator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4ae55f9-77d9-4664-b6d2-d1eaa56b9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.channels = channels\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "                    nn.Conv2d(channels, 64, 4, 2, 1, bias=False),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "                    nn.BatchNorm2d(128),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "                    nn.BatchNorm2d(256),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "                    nn.BatchNorm2d(512),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "                    nn.Sigmoid()\n",
    "                )\n",
    "        \n",
    "    def forward(self,input):\n",
    "        return self.model(input).view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf72800-bc4b-48cb-8666-b86f0a0a3e2e",
   "metadata": {},
   "source": [
    "### TRAIN DCGAN (Deep Convolutional Adversarial Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8b4992c-95b1-4eeb-84af-775416e7c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dcgan(dataloader, num_epochs, latent_dim, lr, beta1):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    netG = Generator(latent_dim, channels=3).to(device)\n",
    "    netD = Discriminator(channels=3).to(device)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    \n",
    "    fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            ############################\n",
    "            # Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            ###########################\n",
    "            netD.zero_grad()\n",
    "            real = data[0].to(device)\n",
    "            batch_size = real.size(0)\n",
    "            label = torch.full((batch_size,), 1, dtype=torch.float, device=device)\n",
    "            \n",
    "            output = netD(real)\n",
    "            errD_real = criterion(output, label)\n",
    "            errD_real.backward()\n",
    "            D_x = output.mean().item()\n",
    "            \n",
    "            noise = torch.randn(batch_size, latent_dim, 1, 1, device=device)\n",
    "            fake = netG(noise)\n",
    "            label.fill_(0.)\n",
    "            output = netD(fake.detach())\n",
    "            errD_fake = criterion(output, label)\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "            errD = errD_real + errD_fake\n",
    "            optimizerD.step()\n",
    "\n",
    "            ############################\n",
    "            # Update G network: maximize log(D(G(z)))\n",
    "            ###########################\n",
    "            netG.zero_grad()\n",
    "            label.fill_(1.)\n",
    "            output = netD(fake)\n",
    "            errG = criterion(output, label)\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            optimizerG.step()\n",
    "            \n",
    "            if i % 50 == 0:\n",
    "                print(f'[{epoch}/{num_epochs}][{i}/{len(dataloader)}] Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f}/{D_G_z2:.4f}')\n",
    "\n",
    "        # Save generated images\n",
    "        with torch.no_grad():\n",
    "            fake = netG(fixed_noise).detach().cpu()\n",
    "            torchvision.utils.save_image(fake, f'fake_samples_epoch_{epoch}.png', normalize=True)\n",
    "\n",
    "    return netG, netD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7d7c2c-2c1e-449e-a993-538b8cf1fd72",
   "metadata": {},
   "source": [
    "# Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "225f132b-515b-4f90-b406-4071bc3be42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
      "[0/5][0/391] Loss_D: 1.4553 Loss_G: 2.0123 D(x): 0.4029 D(G(z)): 0.3968/0.1388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc09a2cf160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ali/Documents/Project/Creative-Art-GAN/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/ali/Documents/Project/Creative-Art-GAN/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/anaconda3/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/anaconda3/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/opt/anaconda3/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/anaconda3/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m generator, discriminator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dcgan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Save the trained models\u001b[39;00m\n\u001b[1;32m     25\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(generator\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 26\u001b[0m, in \u001b[0;36mtrain_dcgan\u001b[0;34m(dataloader, num_epochs, latent_dim, lr, beta1)\u001b[0m\n\u001b[1;32m     24\u001b[0m output \u001b[38;5;241m=\u001b[39m netD(real)\n\u001b[1;32m     25\u001b[0m errD_real \u001b[38;5;241m=\u001b[39m criterion(output, label)\n\u001b[0;32m---> 26\u001b[0m \u001b[43merrD_real\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m D_x \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     29\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, latent_dim, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Documents/Project/Creative-Art-GAN/env/lib/python3.8/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Project/Creative-Art-GAN/env/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Hyperparameters\n",
    "    batch_size = 128\n",
    "    image_size = 64\n",
    "    num_epochs = 5\n",
    "    lr = 0.0002\n",
    "    beta1 = 0.5\n",
    "    latent_dim = 100\n",
    "\n",
    "    # Data loading and preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    dataset = torchvision.datasets.CIFAR10(root='../data', download=True, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    # Train the model\n",
    "    generator, discriminator = train_dcgan(dataloader, num_epochs, latent_dim, lr, beta1)\n",
    "\n",
    "    # Save the trained models\n",
    "    torch.save(generator.state_dict(), 'generator.pth')\n",
    "    torch.save(discriminator.state_dict(), 'discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a918c-bf25-41ef-acf3-e5e7b1d21c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAN",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
